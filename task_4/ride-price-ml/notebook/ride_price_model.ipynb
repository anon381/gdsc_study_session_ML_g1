{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ride Price Estimation System\n",
        "\n",
        "This notebook implements an end-to-end machine learning workflow for estimating ride prices using a custom-designed dataset that I created myself in code. I go through the required steps: problem framing, dataset design and justification, data exploration, cleaning and feature engineering, regression and classification models, evaluation, and ethical reflection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ML Mindset & Problem Framing\n",
        "\n",
        "**Problem type:** Supervised learning, regression (predict continuous `ride_price`).\n",
        "\n",
        "**Real-world scenario:** Estimating the price of a ride (similar to taxi or ride-hailing) based on trip and contextual factors such as distance, duration, time of day, traffic, and demand.\n",
        "\n",
        "**Why ML instead of fixed rules?**\n",
        "- Relationships between features and price are not perfectly linear or obvious.\n",
        "- Factors like traffic, weather, and demand interact in complex ways.\n",
        "- A fixed formula would be brittle and hard to tune, while an ML model can learn patterns from historical data.\n",
        "\n",
        "**What the model should learn:**\n",
        "- Longer distance and duration generally increase price.\n",
        "- Peak hours, high demand, and heavy traffic tend to increase price (e.g., surge-like behavior).\n",
        "- Some conditions (e.g., very bad weather) may add extra fees.\n",
        "\n",
        "In this project we will also create a **classification** target (`high_cost` yes/no) to identify whether a ride is considered expensive compared to typical rides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 2. Imports and basic configuration\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.style.use(\"seaborn-v0_8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Design and Justification\n",
        "\n",
        "I create a synthetic dataset that mimics a ride-hailing platform.\n",
        "\n",
        "**Features (inputs):**\n",
        "1. `distance_km` (numeric): Distance of the trip in kilometers. Longer trips usually cost more.\n",
        "2. `duration_min` (numeric): Trip duration in minutes. Captures time-based pricing (e.g., traffic jams increase time).\n",
        "3. `time_of_day` (categorical: `morning`, `afternoon`, `evening`, `night`): Prices may be higher during peak hours (morning/evening).\n",
        "4. `traffic_level` (categorical: `low`, `medium`, `high`): High traffic increases duration and often price.\n",
        "5. `weather` (categorical: `clear`, `rainy`, `stormy`): Bad weather may increase prices (risk, slower traffic) or extra fees.\n",
        "6. `demand_level` (categorical: `low`, `normal`, `high`): Models surge pricing when demand is high.\n",
        "7. `pickup_zone` (categorical: `city_center`, `suburbs`, `airport`): Some locations (e.g., airport) often have higher base fares.\n",
        "\n",
        "**Target variable:**\n",
        "- `ride_price` (continuous): Final ride price in a chosen currency.\n",
        "\n",
        "**Feature justification summary:**\n",
        "- Distance and duration: core components of almost any ride pricing algorithm.\n",
        "- Time of day and traffic: capture peak hour effects and congestion.\n",
        "- Weather and demand: capture dynamic pricing behavior.\n",
        "- Pickup zone: captures fixed-area surcharges (e.g., airport fees, city-center congestion charges).\n",
        "\n",
        "**Feature considered but excluded:**\n",
        "- `driver_rating` (1–5 stars). I decided **not** to include this because rating is subjective, can be highly biased, and is not typically used directly for pricing in many systems (it is more related to quality control and matching than to fare calculation). Including it could also introduce ethical issues (e.g., unfairly charging more due to biased ratings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 4. Synthetic dataset generation (synthetic data created by me)\n",
        "\n",
        "# NOTE: For the GitHub version of this project, the same logic also exists in\n",
        "# `generate_rides.py`, which saves the dataset to `data/rides.csv`.\n",
        "# Here we regenerate the data inside the notebook so it is fully reproducible.\n",
        "\n",
        "n_samples = 600  # more than the minimum 150 rows for a richer dataset\n",
        "\n",
        "# Numeric features\n",
        "distance_km = np.round(np.random.uniform(1, 25, size=n_samples), 2)  # 1-25 km\n",
        "base_speed_kmph = np.random.normal(30, 5, size=n_samples)  # average speed\n",
        "base_speed_kmph = np.clip(base_speed_kmph, 10, 60)\n",
        "\n",
        "# Duration roughly distance / speed * 60, with some noise\n",
        "true_duration = distance_km / base_speed_kmph * 60\n",
        "noise_duration = np.random.normal(0, 5, size=n_samples)\n",
        "duration_min = np.clip(true_duration + noise_duration, 5, 90)\n",
        "\n",
        "# Categorical features\n",
        "time_of_day = np.random.choice([\"morning\", \"afternoon\", \"evening\", \"night\"], size=n_samples, p=[0.25, 0.3, 0.3, 0.15])\n",
        "traffic_level = np.random.choice([\"low\", \"medium\", \"high\"], size=n_samples, p=[0.3, 0.4, 0.3])\n",
        "weather = np.random.choice([\"clear\", \"rainy\", \"stormy\"], size=n_samples, p=[0.7, 0.25, 0.05])\n",
        "demand_level = np.random.choice([\"low\", \"normal\", \"high\"], size=n_samples, p=[0.2, 0.5, 0.3])\n",
        "pickup_zone = np.random.choice([\"city_center\", \"suburbs\", \"airport\"], size=n_samples, p=[0.4, 0.4, 0.2])\n",
        "\n",
        "# Price construction (not visible to model, only to us):\n",
        "# base fare + distance component + time component + surcharges\n",
        "base_fare = 2.0\n",
        "price_per_km = 0.8\n",
        "price_per_min = 0.3\n",
        "\n",
        "price = base_fare + distance_km * price_per_km + duration_min * price_per_min\n",
        "\n",
        "# Add time-of-day effect\n",
        "for i, tod in enumerate(time_of_day):\n",
        "    if tod in [\"morning\", \"evening\"]:  # peak\n",
        "        price[i] *= 1.15\n",
        "    elif tod == \"night\":\n",
        "        price[i] *= 1.05\n",
        "\n",
        "# Add traffic effect\n",
        "for i, tl in enumerate(traffic_level):\n",
        "    if tl == \"high\":\n",
        "        price[i] *= 1.2\n",
        "    elif tl == \"medium\":\n",
        "        price[i] *= 1.05\n",
        "\n",
        "# Add weather effect\n",
        "for i, w in enumerate(weather):\n",
        "    if w == \"rainy\":\n",
        "        price[i] *= 1.05\n",
        "    elif w == \"stormy\":\n",
        "        price[i] *= 1.15\n",
        "\n",
        "# Add demand effect (surge)\n",
        "for i, d in enumerate(demand_level):\n",
        "    if d == \"high\":\n",
        "        price[i] *= 1.3\n",
        "    elif d == \"low\":\n",
        "        price[i] *= 0.9\n",
        "\n",
        "# Add pickup zone effect\n",
        "for i, z in enumerate(pickup_zone):\n",
        "    if z == \"airport\":\n",
        "        price[i] += 5  # airport surcharge\n",
        "    elif z == \"city_center\":\n",
        "        price[i] += 1.5\n",
        "\n",
        "# Add random noise\n",
        "price = price + np.random.normal(0, 2.5, size=n_samples)\n",
        "price = np.round(np.clip(price, 5, None), 2)\n",
        "\n",
        "# Build DataFrame\n",
        "data = pd.DataFrame({\n",
        "    \"distance_km\": distance_km,\n",
        "    \"duration_min\": duration_min,\n",
        "    \"time_of_day\": time_of_day,\n",
        "    \"traffic_level\": traffic_level,\n",
        "    \"weather\": weather,\n",
        "    \"demand_level\": demand_level,\n",
        "    \"pickup_zone\": pickup_zone,\n",
        "    \"ride_price\": price,\n",
        "})\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load / Save Dataset\n",
        "\n",
        "To keep the project reproducible and **separate code from data**, I:\n",
        "\n",
        "- Generate the synthetic data in this notebook.\n",
        "- Save it to `../data/rides.csv` so that it can be reused and submitted to GitHub.\n",
        "- In a real project, this step would be replaced by loading a real CSV exported from a database or data warehouse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Save dataset to CSV for the repository (relative to this notebook)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "csv_path = Path(\"../data/rides.csv\")\n",
        "csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "data.to_csv(csv_path, index=False)\n",
        "print(\"Saved CSV to:\", csv_path.resolve())\n",
        "\n",
        "# (Optional) reload from CSV to show that it works\n",
        "loaded = pd.read_csv(csv_path)\n",
        "loaded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Exploration & Understanding\n",
        "\n",
        "In this section, I inspect the dataset to understand its structure and quality.\n",
        "I look at:\n",
        "\n",
        "- Basic info (column types, non-null counts)\n",
        "- Summary statistics for numerical variables\n",
        "- Category distributions for categorical variables\n",
        "- Simple visualizations to understand relationships and potential outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Basic info\n",
        "print(\"Shape:\", data.shape)\n",
        "print(\"\\nInfo:\")\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Summary statistics for numeric columns\n",
        "numeric_cols = [\"distance_km\", \"duration_min\", \"ride_price\"]\n",
        "data[numeric_cols].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Category distributions\n",
        "cat_cols = [\"time_of_day\", \"traffic_level\", \"weather\", \"demand_level\", \"pickup_zone\"]\n",
        "for col in cat_cols:\n",
        "    print(f\"\\nValue counts for {col}:\")\n",
        "    print(data[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizations: relationships and outliers\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "sns.scatterplot(ax=axes[0], x=\"distance_km\", y=\"ride_price\", data=data, alpha=0.6)\n",
        "axes[0].set_title(\"Distance vs Ride Price\")\n",
        "\n",
        "sns.scatterplot(ax=axes[1], x=\"duration_min\", y=\"ride_price\", data=data, alpha=0.6)\n",
        "axes[1].set_title(\"Duration vs Ride Price\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot for price distribution and potential outliers\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.boxplot(y=\"ride_price\", data=data)\n",
        "plt.title(\"Ride Price Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the plots and summaries we can see:\n",
        "\n",
        "- `ride_price` increases with both `distance_km` and `duration_min`, as expected.\n",
        "- The boxplot shows a few high-price rides, which come from long trips during peak time, heavy traffic, or bad weather.\n",
        "- The categorical features are reasonably balanced (no category is extremely rare), which is good for model training.\n",
        "\n",
        "Next, we formalize the preprocessing steps so that data cleaning and feature engineering are done **inside a reproducible pipeline**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Cleaning & Feature Engineering\n",
        "\n",
        "Here I prepare the data for modeling. I:\n",
        "\n",
        "- Separate features (`X`) and target (`y`).\n",
        "- Define which columns are numerical vs categorical.\n",
        "- Build a preprocessing pipeline that:\n",
        "  - Imputes missing values (mean for numeric, most frequent for categorical) – important for real data even if our synthetic data has no missing values.\n",
        "  - Scales numerical features (so that distance and duration are on a comparable scale).\n",
        "  - One-hot encodes categorical variables (so models can use them).\n",
        "\n",
        "Poor data quality (missing values, wrong labels, extreme outliers) could:\n",
        "- Make the model learn noise instead of real patterns.\n",
        "- Lead to unstable or biased predictions.\n",
        "- Reduce generalization to new, unseen rides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Split features and target\n",
        "X = data.drop(columns=[\"ride_price\"])\n",
        "y = data[\"ride_price\"]\n",
        "\n",
        "numeric_features = [\"distance_km\", \"duration_min\"]\n",
        "categorical_features = [\"time_of_day\", \"traffic_level\", \"weather\", \"demand_level\", \"pickup_zone\"]\n",
        "\n",
        "# Preprocessing for numeric data: impute (mean) + scale\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Preprocessing for categorical data: impute (most frequent) + one-hot encode\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Combine into a ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Regression Model: Price Prediction (Linear Regression)\n",
        "\n",
        "I now train a **Linear Regression** model to predict the continuous `ride_price`.\n",
        "\n",
        "Steps:\n",
        "- Split the data into training and test sets (80% / 20%).\n",
        "- Use the preprocessing pipeline defined above.\n",
        "- Fit a Linear Regression model.\n",
        "- Evaluate using RMSE (root mean squared error) and R².\n",
        "- Plot predicted vs actual prices to visually inspect performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Train-test split for regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "len(X_train), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Build regression pipeline: preprocessing + linear regression\n",
        "regression_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R^2 : {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Plot predicted vs actual prices\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Actual vs Predicted Ride Prices (Linear Regression)\")\n",
        "lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "plt.plot(lims, lims, \"--\", color=\"red\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The regression model achieves a relatively low RMSE and a high R² on this synthetic dataset, which is expected because the data was generated using a mostly linear pricing rule.\n",
        "\n",
        "The scatter plot shows that most points lie close to the red diagonal line, meaning predicted prices are close to the true prices. A few deviations are caused by the random noise we added when generating the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
